{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOVnHEDHrPARbcR8dLctpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emielrobben/Capstone_AUC/blob/master/DAIS_Ass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FI5GH7tQ3-2",
        "outputId": "3ea19218-c798-4195-94e8-10ae98d9c57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AItools'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 67.15 KiB | 1.32 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "/content/AItools\n",
            "Cities.zip  DAIS_Ass3.ipynb  README.md\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MahdiTheGreat/AItools.git\n",
        "%cd AItools\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"Cities.zip\" -d \"DAIS_Ass3\"\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdW88mhQRF6v",
        "outputId": "867db131-e2ef-4a92-9ab2-effc3dc32769"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Cities.zip\n",
            "  inflating: DAIS_Ass3/Chengdu_labeled.csv  \n",
            "  inflating: DAIS_Ass3/Shenyang_labeled.csv  \n",
            "  inflating: DAIS_Ass3/Beijing_labeled.csv  \n",
            "  inflating: DAIS_Ass3/Guangzhou_labeled.csv  \n",
            "  inflating: DAIS_Ass3/Shanghai_labeled.csv  \n",
            "Cities.zip  \u001b[0m\u001b[01;34mDAIS_Ass3\u001b[0m/  DAIS_Ass3.ipynb  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check the extracted folder structure\n",
        "print(os.listdir(\"DAIS_Ass3\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yAJtuiMS41j",
        "outputId": "007a5d08-772e-4b4d-8f80-c64b2f2b3e98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Guangzhou_labeled.csv', 'Chengdu_labeled.csv', 'Shanghai_labeled.csv', 'Shenyang_labeled.csv', 'Beijing_labeled.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the extracted data folder\n",
        "data_folder = \"DAIS_Ass3\"\n",
        "\n",
        "# Corrected filenames\n",
        "city_files = {\n",
        "    \"Beijing\": \"Beijing_labeled.csv\",\n",
        "    \"Shenyang\": \"Shenyang_labeled.csv\",\n",
        "    \"Guangzhou\": \"Guangzhou_labeled.csv\",\n",
        "    \"Shanghai\": \"Shanghai_labeled.csv\"\n",
        "}\n",
        "\n",
        "# Load data\n",
        "city_data = {city: pd.read_csv(os.path.join(data_folder, filename)) for city, filename in city_files.items()}\n",
        "\n",
        "# Extract relevant features and target variable\n",
        "feature_columns = [col for col in city_data[\"Beijing\"].columns if col != \"PM_HIGH\"]\n",
        "\n",
        "# Create training and test sets\n",
        "X_train = pd.concat([city_data[\"Beijing\"][feature_columns], city_data[\"Shenyang\"][feature_columns]])\n",
        "Y_train = pd.concat([city_data[\"Beijing\"][\"PM_HIGH\"], city_data[\"Shenyang\"][\"PM_HIGH\"]])\n",
        "\n",
        "X_test = pd.concat([city_data[\"Guangzhou\"][feature_columns], city_data[\"Shanghai\"][feature_columns]])\n",
        "Y_test = pd.concat([city_data[\"Guangzhou\"][\"PM_HIGH\"], city_data[\"Shanghai\"][\"PM_HIGH\"]])\n",
        "\n",
        "# Convert to NumPy arrays (if needed for scikit-learn)\n",
        "X_train, Y_train = X_train.values, Y_train.values\n",
        "X_test, Y_test = X_test.values, Y_test.values\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt5oL9qrSPiz",
        "outputId": "62c767b5-87e6-443c-8457-1660674800b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (2895, 10)\n",
            "Test data shape: (2703, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans #https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class Classifier:\n",
        "    def __init__(self, n_clusters):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        self.centroid_labels = {}\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        # Step 1: Apply K-means clustering\n",
        "        self.kmeans.fit(X)\n",
        "        cluster_assignments = self.kmeans.labels_\n",
        "\n",
        "        # Step 2: Assign a majority label to each centroid\n",
        "        self.centroid_labels = {}  # Reset before training\n",
        "\n",
        "        for cluster_id in range(self.n_clusters):\n",
        "            # Get all training labels assigned to this cluster\n",
        "            cluster_indices = np.where(cluster_assignments == cluster_id)[0]\n",
        "            cluster_labels = Y[cluster_indices]\n",
        "\n",
        "            # Find the majority label (0 or 1) in this cluster\n",
        "            if len(cluster_labels) > 0:\n",
        "                most_common_label = Counter(cluster_labels).most_common(1)[0][0]\n",
        "                self.centroid_labels[cluster_id] = most_common_label\n",
        "\n",
        "        print(\"Model trained with\", self.n_clusters, \"clusters.\")\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predicts labels for new data points based on the nearest cluster centroid. \"\"\"\n",
        "        # Step 1: Find the nearest cluster for each point\n",
        "        cluster_assignments = self.kmeans.predict(X)\n",
        "\n",
        "        # Step 2: Assign the label of the corresponding cluster\n",
        "        predictions = np.array([self.centroid_labels[cluster] for cluster in cluster_assignments])\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def score(self, X, Y):\n",
        "        \"\"\" Evaluates the accuracy of the classifier. \"\"\"\n",
        "        predictions = self.predict(X)  # Get model predictions\n",
        "        accuracy = accuracy_score(Y, predictions)  # Compare with true labels\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "# Create an instance of the classifier with a chosen number of clusters\n",
        "C = Classifier(n_clusters=10)  # Tune K as needed\n",
        "\n",
        "# Fit the model on the training data (Beijing & Shenyang)\n",
        "C.fit(X_train, Y_train)\n",
        "\n",
        "# Predict on the test set (Guangzhou & Shanghai)\n",
        "predictions = C.predict(X_test)\n",
        "print(\"Predictions:\", predictions)\n",
        "\n",
        "# Calculate and print accuracy on both training and test sets\n",
        "train_score = C.score(X_train, Y_train)\n",
        "test_score = C.score(X_test, Y_test)\n",
        "\n",
        "print(f\"Training Accuracy: {train_score:.4f}\")\n",
        "print(f\"Test Accuracy: {test_score:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rrPHMgRRRi9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01aaffb9-2b9d-4ecb-b61e-4a74dd724d52"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained with 10 clusters.\n",
            "Predictions: [0. 0. 0. ... 1. 1. 1.]\n",
            "Training Accuracy: 0.7472\n",
            "Test Accuracy: 0.8824\n"
          ]
        }
      ]
    }
  ]
}